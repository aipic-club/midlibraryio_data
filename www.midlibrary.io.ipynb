{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install aiohttp\n",
    "!{sys.executable} -m pip install aiofiles\n",
    "!{sys.executable} -m pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import aiofiles\n",
    "import glob\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def fetch(url: str) -> BeautifulSoup:\n",
    "    loop = asyncio.get_event_loop()\n",
    "    async with aiohttp.ClientSession(connector=aiohttp.TCPConnector(ssl=False), loop=loop) as session:\n",
    "        print(f'fetch url contents: {url}')\n",
    "        async with session.get(url=url) as resp:\n",
    "            #print(resp.status)\n",
    "            text = await resp.text()\n",
    "            return BeautifulSoup(text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def download_image(url, save_path):\n",
    "    loop = asyncio.get_event_loop()\n",
    "    async with aiohttp.ClientSession(connector=aiohttp.TCPConnector(ssl=False ), loop=loop) as session:\n",
    "        print(f'download image: {url}')\n",
    "        async with session.get(url) as response:\n",
    "            if response.status == 200:\n",
    "                async with aiofiles.open(save_path, mode='wb') as file:\n",
    "                    while True:\n",
    "                        chunk = await response.content.read(1024)\n",
    "                        if not chunk:\n",
    "                            break\n",
    "                        await file.write(chunk)\n",
    "                print(f\"Image downloaded and saved to: {save_path}\")\n",
    "            else:\n",
    "                print(f\"Failed to download image: {response.status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def save_image(src: str, folder: str , name: str) -> str:\n",
    "    loop = asyncio.get_event_loop()\n",
    "    cwd = os.getcwd()\n",
    "    folder_path = os.path.join('data', 'images', folder)\n",
    "    file_path = os.path.join(folder_path , f'{name.strip()}.jpg')\n",
    "    os.makedirs(os.path.join(cwd, folder_path), exist_ok=True)\n",
    "    output_path = os.path.join(cwd, file_path)\n",
    "    if not os.path.exists(output_path):\n",
    "        asyncio.run_coroutine_threadsafe(download_image(src,  output_path ), loop=loop)\n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_categories():\n",
    "    soup = await fetch(url='https://www.midlibrary.io/categories')\n",
    "    div_listitems = soup.find_all(\"div\", attrs={\"class\": \"cat-item\"})\n",
    "    data = []\n",
    "    for item in div_listitems:\n",
    "        child_element = item.find(\"a\")\n",
    "        link = child_element.attrs.get(\"href\")\n",
    "        children = list(child_element.children)\n",
    "        src = children[0].attrs.get('src')\n",
    "        name = children[1].find(\"div\").find(\"div\").text\n",
    "        data.append({\n",
    "            'name': name,\n",
    "            'cover': await save_image(src=src, folder= 'categories', name= name),\n",
    "            'link': link\n",
    "        })\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_category(link: str, suffix: str = ''):\n",
    "    url = f'https://www.midlibrary.io/{link}{suffix}'\n",
    "    soup = await fetch(url= url)\n",
    "    page = soup.find(\"a\", attrs={\"class\": \"w-pagination-next\"})\n",
    "    all_styles = soup.find(\"div\", attrs={\"class\": \"shelf-3\"})\n",
    "\n",
    "    items = all_styles.find_all(\"div\", attrs={\"role\": \"listitem\", \"class\": \"cat-item-2 w-dyn-item\"})\n",
    "    data  = []\n",
    "    for item in items:\n",
    "        a = item.find(\"a\", attrs={\"class\":\"cat-link w-inline-block\"})\n",
    "        href = a.attrs.get(\"href\")\n",
    "        img = a.find(\"img\")\n",
    "        src = img.attrs.get(\"src\")\n",
    "        name = item.find(\"div\",attrs={\"fs-cmssort-field\": \"name\"}).text\n",
    "        sub = item.find(\"div\", attrs={\"fs-cmsfilter-field\": \"sections\"})\n",
    "        sub_title = sub.text if sub else None\n",
    "\n",
    "        if src is None:\n",
    "            print(name)\n",
    "        \n",
    "        data.append({\n",
    "            'name': name,\n",
    "            'cover': await save_image(src=src, folder= link, name= name),\n",
    "            'link': href,\n",
    "            'sub_category': sub_title\n",
    "        })\n",
    "\n",
    "    if page:\n",
    "        data += await get_category(link=link, suffix=page.attrs.get(\"href\"))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_page(link: str):\n",
    "    url = f'https://www.midlibrary.io/{link}'\n",
    "    soup = await fetch(url= url)\n",
    "    hero = soup.find(\"div\" , attrs={\"class\":\"hero-275\"})\n",
    "    bio = soup.find(\"div\", attrs={\"class\": \"_3-bio\"})\n",
    "\n",
    "    samples = soup.find_all(\"div\", attrs={\"class\": \"sample\"})\n",
    "    output = {\n",
    "        'hero': None,\n",
    "        'bio': bio.text if bio else None\n",
    "    }\n",
    "    if hero is not None:\n",
    "        hero_img_src = hero.find(\"img\").attrs.get(\"src\")\n",
    "        output[\"hero\"] = await save_image(src=hero_img_src, folder= link, name= 'hero')\n",
    "\n",
    "\n",
    "    data = []\n",
    "\n",
    "    for sample in samples:\n",
    "        img = sample.find(\"img\")\n",
    "        img_src=  img.attrs.get(\"src\")\n",
    "        copy_items = sample.find(\"div\", attrs = {\"class\": \"copy3\"})\n",
    "        prompt =  copy_items.text\n",
    "        name = prompt\n",
    "        data.append({\n",
    "            'cover': await save_image(src=img_src, folder= link, name= name),\n",
    "            'prompt': prompt\n",
    "        })\n",
    "    output['samples'] = data\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "file_pattern = 'data/json/categories/*.json'\n",
    "data = []\n",
    "for file_name in glob.glob(file_pattern):\n",
    "    with open(file_name) as file:\n",
    "        data += json.load(file)\n",
    "\n",
    "folder_path = os.path.join(os.getcwd(), 'data', 'json', 'styles')\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "count = len(data)\n",
    "i = 0\n",
    "for item in data:\n",
    "    i+=1\n",
    "    link = item.get(\"link\").replace(\"/\",\"\",1)\n",
    "\n",
    "    print(f'get link {link}, current: {i} / {count}')\n",
    "\n",
    "    data = await get_page(link= link)\n",
    "    json_data = json.dumps(data)\n",
    "    name = link.split(\"/\")[-1]\n",
    "    async with aiofiles.open(os.path.join(folder_path,  f'{name}.json' ), mode='w') as f:\n",
    "        await f.write(json_data)\n",
    "\n",
    "\n",
    "\n",
    "#await get_page(link= 'styles/3d-graffiti')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    data = await get_categories()\n",
    "    json_data = json.dumps(data)\n",
    "    folder_path = os.path.join(os.getcwd(), 'data', 'json')\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    async with aiofiles.open(os.path.join(folder_path, 'categories.json' ), mode='w') as f:\n",
    "        await f.write(json_data)  \n",
    "\n",
    "await main()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def start_download_category(link: str):\n",
    "    data = await get_category(link = link)\n",
    "    json_data = json.dumps(data)\n",
    "    folder_path = os.path.join(os.getcwd(), 'data', 'json', 'categories')\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    async with aiofiles.open(os.path.join(os.getcwd(), 'data', 'json',  f'{link}.json' ), mode='w') as f:\n",
    "        await f.write(json_data)  \n",
    "\n",
    "async def main():\n",
    "    async with aiofiles.open(os.path.join(os.getcwd(), 'data', 'json', 'categories.json' ), mode='r') as f:\n",
    "        contents = await f.read()\n",
    "        categories = json.loads(contents)\n",
    "        for categoriy in categories:\n",
    "            link = categoriy.get(\"link\").replace(\"/\", \"\", 1)\n",
    "            print(link)\n",
    "            await start_download_category(link=link)\n",
    "\n",
    "await main()     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
